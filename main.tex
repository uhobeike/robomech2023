\documentclass{jarticle}
\usepackage{robomech}
\usepackage{graphicx}

\usepackage{mathrsfs}
\usepackage{bm}

\begin{document}
\makeatletter
\title{未知障害物環境に対応するための\\モンテカルロ自己位置推定における観測範囲の選択}
{―まだ決まってない―}
{Observation Range Selection in Monte Carlo localization for Unknown Obstacle Environments}
{-Not decided yet.-}

\author{
\begin{tabular}{ll}
 ○学\hspace{1zw} 池邉龍宏（千葉工大）& 正\hspace{1zw}林原靖男\hspace{1zw} (千葉工大)\\
 \hspace{1zw}正\hspace{1zw}上田隆一（千葉工大）\\
 % ※協賛・後援団体の会員資格で発表される場合は「正・学」は不要です。
 \end{tabular}
 % &\\
 \vspace{1zh} \\
 \begin{tabular}{l}
{\small Tatsuhiro IKEBE, Chiba Institute of Technology, 
 }\\
 {\small Yasuo HAYASHIBARA, Chiba Institute of Technology}\\
 {\small Ryuichi UEDA, Chiba Institute of Technology}\\
\end{tabular}
}
\makeatother

\abstract{ \small 
Not decided yet.
}

\date{} % 日付を出力しない
\keywords{Autonomous mobile robots, Navigation, LiDAR Localization, MCL, Unknown Obstacle}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


\section{緒言}%===========================

近年、自律移動ロボットの自己位置推定手法として、 Monte Carlo localization（MCL）\cite{MCL}
がよく用いられる。MCLは、ロボットの姿勢$\mathcal{X}$を多数のパーティクルで近似し、
推定した姿勢$\bm{x}$${ = (x, y, \Theta)}$を出力とするアルゴリズムである。
また、MCLはマルチモーダルな分布を持つことができ、割と強い自己位置推定だよー。
しかし、MCLのアルゴリズムでは、実環境に存在する未知障害物の対策は出来ていない。
そのため、未知障害物が存在する環境では、自己位置推定が破綻しやすい。
ここでいう未知障害物とは、ロボットが持っている地図（静的障害物）以外の障害物のことである。

　そのような環境の例としては、つくばチャレンジ\cite{つくばチャレンジ}が挙げられる。つくばチャレンジというのは、
実際に人や自動車が通る横断歩道、公園において、ロボットを約2km自律走行させる技術チャレンジです。
図\ref{fig: つくばチャレンジ人混み}は、つくばチャレンジのスタート地点である。
このような人混みがすごいような環境は、ロボットが持っている地図とLiDAR等の
センサから得られるデータとの照合の際に失敗する可能性が高い。
照合に失敗した場合、結果的にそれが原因で自己位置推定が破綻する。

　そのような問題に対応するためにいくつか研究がある。
xとyとzが存在する。xはこんな感じ、yはこんな感じ、zはこんな感じである。

　zの研究の未知障害物を観測に含めないことで、自己位置推定の破綻を防ぐということから
MCLのアルゴリズムレベルで対策を行うためのアイデアを得た。
そこで、本稿では、その性能について実験にて評価を行う。
2章では、未知障害物対策を実装したMCL、3章では実装したMCLの性能評価を行うための実験、
4章では結果から性評価を行い、最後に結言で本稿をまとめる。

\begin{figure}[h]
  \centering
   \includegraphics[height=38mm]{fig/hitogomi.eps}
   \vspace*{-4mm}
   \caption{Crowds at the start of the Tsukuba Challenge 2022}
   \label{fig: つくばチャレンジ人混み}
 \end{figure}

\section{手法}%===========================

　主なアルゴリズムの流れを図\ref{fig: つくばチャレンジ人混み}に示す。
初期化の部分で各パーティクルごとにランダムな観測範囲を付与する。
次に、動作モデルと観測モデルによる更新、リサンプリングを行うことで、
未知障害物が含まれていないような観測範囲をMCLのアルゴリズムによって求める。


\subsection{各パーティクルの初期化}

各パーティクルの初期化時に各パーティクルに対して、
ランダムな観測を与える。
ランダムな観測とは、360°のうちの、ある角度分を観測としたものである。

\subsection{動作モデル}

動作モデルは、MCLのアルゴリズム通りである。

\subsection{観測モデル}

観測モデルでは、各パーティクルの入力として、生の観測を受け取る。
観測を受け取り、各パーティクルはランダムな観測範囲を元に観測を間引く。
間引いた観測を元に尤度場から、そのパーティクルの尤度を求める。
尤度をかけ合わせたものをそのパーティクルの重みとする。

\subsection{リサンプリング}

リサンプリングでは、パーティクルの重みの正規化を行う。
また、1割程度の各パーティクルに対してランダムな観測範囲を再付与させる。
これは、各パーティクルがある観測範囲を選択し続ける問題を避けることが目的である。

\section{実験}%===========================

\subsection{実験環境}

実験環境について、図\ref{fig: つくばチャレンジ人混み}に示す。
実験は、図\ref{fig: つくばチャレンジ人混み}のつくばチャレンジでの人混みの環境を模した
図\ref{fig: つくばチャレンジ人混みシミュレータ}のシミュレータ環境で行う。
シミュレータにはGazebo、ナビゲーションのシステムにROS Noeticを使用する。
今回、実験に用いるロボットは差動二輪型のロボットである。

\begin{table}[hbtp]
  \caption{experimental environment}
  \label{table:data_type}
  \centering
  \begin{tabular}{lcr}
    \hline
    CPU & Core™ i9-12900K × 24 \\
    GPU & GeForce RTX 2060 \\
    Ubuntu & 20.04 \\
    ROS  & Noetic \\
    Gazebo  &  9.0 \\
    \hline
  \end{tabular}
\end{table}

\begin{figure}[h]
  \centering
   \includegraphics[height=140mm]{fig/simulator.eps}
   \vspace*{-4mm}
   \caption{A simulator that mimics the crowds at the start of Tsukuba Challenge 2022}
   \label{fig: つくばチャレンジ人混みシミュレータ}
 \end{figure}

\subsection{実験方法}

とする。

そのため、今回の実験での評価項目は以下のようになる。

\begin{itemize}
  \item スタートからゴールまでの完走率
  \begin{itemize}
    \item 未知障害物対応に最適な観測範囲
  \end{itemize}
  \item スタートからゴールまで走行したときの真値との比較
  \item 計算時間
\end{itemize}

\section{実験結果}%===========================

表\ref{table:data_type}に完走率の結果を示す。
試行量が足りているかということについては、
図\ref{fig: つくばチャレンジ人混み}を見ていただきたい。
各完走率の分布がはっきり別れているので



\section{結言}%===========================


\footnotesize
\begin{thebibliography}{99}

\bibitem{MCL}

\bibitem{つくばチャレンジ}

\bibitem{Shinjuku99}

\end{thebibliography}

\normalsize
\end{document}
